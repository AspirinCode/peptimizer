{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "from rdkit import DataStructs\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv1D, Dense, Flatten, BatchNormalization, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTOR_DATASET = './dataset/predictor_dataset.csv'\n",
    "\n",
    "VAL_SPLIT = .20\n",
    "\n",
    "#Parameters for fingerprint generation\n",
    "RADIUS = 3\n",
    "NBITS = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PREDICTOR_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fingerprint_Generation:\n",
    "    def __init__(self, smiles,radius=RADIUS,nbits=NBITS):\n",
    "        self.lookupfps = {}\n",
    "        \n",
    "        for key, value in lookupsmiles.items():\n",
    "            mol = Chem.MolFromSmiles(value)\n",
    "            fp = np.array(Chem.GetMorganFingerprintAsBitVect(mol,radius,nbits))\n",
    "            self.lookupfps[key] = fp\n",
    "        self.lookupfps[' '] = np.zeros(self.lookupfps['A'].shape)\n",
    "    \n",
    "    def seq(self, seq):\n",
    "        fp = np.asarray([self.lookupfps[seq[i]] for i in range(len(seq))])\n",
    "        return fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookupsmiles = {\n",
    "         '2': 'NC(CSC1=C(F)C(F)=C(C(F)=C1F)C1=C(F)C(F)=C(SCC(N)C(N)=O)C(F)=C1F)C(N)=O',\n",
    "         '3': 'CC(=O)CC1=CN(CCCCC(N)C(N)=O)N=N1',\n",
    "         'A': 'N[C@@H](C)C(O)=O',\n",
    "         'B': 'C(CN)C(=O)O',\n",
    "         'X': 'C(CCC(=O)O)CCN',\n",
    "         'R': 'N[C@@H](CCCNC(N)=N)C(O)=O', \n",
    "         'N': 'N[C@@H](CC(N)=O)C(O)=O', \n",
    "         'D': 'N[C@@H](CC(O)=O)C(O)=O', \n",
    "         'C': 'N[C@H](C(O)=O)CS', \n",
    "         'E': 'N[C@@H](CCC(O)=O)C(O)=O', \n",
    "         'Q': 'N[C@@H](CCC(N)=O)C(O)=O', \n",
    "         'G': 'NCC(O)=O', \n",
    "         'H': 'N[C@@H](CC1=CNC=N1)C(O)=O', \n",
    "         'I': 'N[C@@H]([C@@H](C)CC)C(O)=O', \n",
    "         'L': 'N[C@@H](CC(C)C)C(O)=O', \n",
    "         'K': 'N[C@@H](CCCCN)C(O)=O', \n",
    "         'M': 'N[C@@H](CCSC)C(O)=O', \n",
    "         'F': 'N[C@@H](CC1=CC=CC=C1)C(O)=O', \n",
    "         'P': 'O=C(O)[C@H]1NCCC1', \n",
    "         'S': 'N[C@@H](CO)C(O)=O', \n",
    "         'T': 'N[C@@H]([C@H](O)C)C(O)=O', \n",
    "         'W': 'N[C@@H](CC1=CNC2=C1C=CC=C2)C(O)=O', \n",
    "         'Y': 'N[C@@H](CC1=CC=C(O)C=C1)C(O)=O', \n",
    "         'V': 'N[C@@H](C(C)C)C(O)=O',\n",
    "         '@': 'N[C@@H](CSC1=C(C(F)=C(C(F)=C1F)C2=C(C(F)=C(C(F)=C2F)SC[C@@H](C(O)=O)N)F)F)C(O)=O',\n",
    "         '#': 'N[C@H](C(O)=O)CSC1=CC(SC[C@@H](N)C(O)=O)=CC(SC[C@H](N)C(O)=O)=C1'\n",
    "}\n",
    "\n",
    "fp = Fingerprint_Generation(lookupsmiles) #Instantiating Fingerprint_Generation Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(columns=['sequence', 'feature'])\n",
    "Y_df = pd.DataFrame(columns=['intensity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_max = 108\n",
    "\n",
    "for i in range(0, df.shape[0]):\n",
    "    X_df.at[i, 'sequence'] = df['sequences'][i]\n",
    "    X_df.at[i, 'feature'] = fp.seq(df['sequences'][i])\n",
    "    \n",
    "    Y_df.at[i, 'intensity'] = df['intensity'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, X_df.shape[0]):\n",
    "    n_rows = features_max - len(X_df.at[i, 'feature'])\n",
    "    shape_padding = (n_rows, NBITS)\n",
    "    padding_array = np.zeros(shape_padding)\n",
    "    X_df.at[i, 'feature'] = np.concatenate((X_df.at[i, 'feature'], padding_array), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnX = np.ndarray(shape=(X_df.shape[0],features_max,NBITS), dtype=int)\n",
    "for i in range(0,X_df.shape[0]):\n",
    "    nnX[i] = X_df.at[i, 'feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data = {}\n",
    "dict_data['mean_Intensity'] = Y_df['intensity'].mean()\n",
    "dict_data['std_Intensity'] = Y_df['intensity'].std()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Y_df.fillna(0, inplace=True) #There are few missing values in the Spreadsheet, so replacing them with 0\n",
    "Y_df[['intensity']] = scaler.fit_transform(Y_df[['intensity']])\n",
    "\n",
    "Y_Intensity = np.asarray(Y_df['intensity'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.RandomState(seed=108).permutation(np.arange(nnX.shape[0]))\n",
    "\n",
    "nnX = nnX[indices]\n",
    "Y_Intensity = Y_Intensity[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnX_valid = nnX[indices][-int(len(indices)*VAL_SPLIT):]\n",
    "Y_Intensity_valid = Y_Intensity[indices][-int(len(indices)*VAL_SPLIT):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = None\n",
    "Y_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "DIM = 256\n",
    "SIZE = 2\n",
    "\n",
    "model.add(Conv1D(DIM, SIZE, input_shape=(features_max,NBITS)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv1D(DIM, SIZE))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(DIM, SIZE))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(DIM))\n",
    "model.add(Activation('softplus'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "optimizer = Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = './model/predictor/epoch-{epoch:02d}-loss-{loss:.4f}-val_loss-{val_loss:.4f}-.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print (model.summary())\n",
    "\n",
    "model.fit(nnX, Y_Intensity, batch_size=25, epochs=2, validation_split=VAL_SPLIT, \n",
    "          callbacks=callbacks_list, \n",
    "          verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter((Y_Intensity_valid*dict_data['std_Intensity'])+dict_data['mean_Intensity'],\n",
    "            (model.predict(nnX_valid)*dict_data['std_Intensity'])+dict_data['mean_Intensity'])\n",
    "# plt.plot(np.linspace(0,20,100), np.linspace(0,20,100), '-')\n",
    "\n",
    "plt.ylabel('Predicted Intensity', fontdict={'size':16})\n",
    "plt.xlabel('Experimental Intensity', fontdict={'size':16})\n",
    "plt.tick_params(labelsize=14)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
